{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "\n",
    "(True/False) A linear classifier can only learn positive coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "\n",
    "(True/False) In order to train a logistic regression model, we find the weights that maximize the likelihood of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "(True/False) The data likelihood is the product of the probability of the inputs x given the weights w and response y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "Calculate the likelihood of this data. \n",
    "\n",
    "x=[2.5,0.3,2.8,0.5]\t \n",
    "\n",
    "y=[+1,-1,+1,+1]               \n",
    "\n",
    "Round your answer to 2 decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import exp\n",
    "\n",
    "def score(x,w=0,w1=1):\n",
    "    value=w+x*w1\n",
    "    return value\n",
    "\n",
    "def sigmoid(value): #probability\n",
    "    sigmoid_value=1.0/(1+exp(-value))\n",
    "    return sigmoid_value\n",
    "\n",
    "def likelyhood(df,w=0,w1=1):\n",
    "    likelyhood_value=1\n",
    "    for itr in range(len(df)):\n",
    "        if df[\"label\"].iloc[itr]==1:\n",
    "            likelyhood_value=likelyhood_value*(sigmoid(score(df[\"values\"].iloc[itr],w,w1)))\n",
    "        else:\n",
    "            likelyhood_value=likelyhood_value*(1-sigmoid(score(df[\"values\"].iloc[itr],w,w1)))\n",
    "            \n",
    "    return round(likelyhood_value,2)\n",
    "\n",
    "\n",
    "x=np.asarray([2.5,0.3,2.8,0.5])\n",
    "y=np.asarray([1,0,1,1])\n",
    "\n",
    "df=pd.DataFrame.from_dict({\"values\":x,\"label\":y})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "likelyhood(df,0,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "\n",
    "Refer to the scenario given in Question 4 to answer the following:\n",
    "\n",
    "Calculate the derivative of the log likelihood with respect to w1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def derivative_at_point(hx,indicator_function_value):\n",
    "    derivative=hx*(indicator_function_value-sigmoid(score(hx)))\n",
    "    return derivative\n",
    "\n",
    "def derivative_sum(df):\n",
    "    sum_var=0\n",
    "    for itr in range(len(df)):\n",
    "        sum_var=sum_var+derivative_at_point(df[\"values\"].iloc[itr],df[\"label\"].iloc[itr])\n",
    "    \n",
    "    return round(sum_var,2)\n",
    "\n",
    "derivative_sum(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "\n",
    "Which of the following is true about gradient ascent? Select all that apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__:\n",
    "\n",
    "    1) It is an iterative algorithm\n",
    "    3) It finds the maximum by “hill climbing”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
