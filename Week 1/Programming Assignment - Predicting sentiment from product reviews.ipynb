{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment from product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries Import\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"Chained_Assignment\",None)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataframe\n",
    "dataframe=pd.read_csv(\"amazon_baby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                           Planetwise Flannel Wipes   \n",
       "1                              Planetwise Wipe Pouch   \n",
       "2                Annas Dream Full Quilt with 2 Shams   \n",
       "3  Stop Pacifier Sucking without tears with Thumb...   \n",
       "4  Stop Pacifier Sucking without tears with Thumb...   \n",
       "\n",
       "                                              review  rating  \n",
       "0  These flannel wipes are OK, but in my opinion ...       3  \n",
       "1  it came early and was not disappointed. i love...       5  \n",
       "2  Very soft and comfortable and warmer than it l...       5  \n",
       "3  This is a product well worth the purchase.  I ...       5  \n",
       "4  All of my kids have cried non-stop when I trie...       5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      "name      183213 non-null object\n",
      "review    182702 non-null object\n",
      "rating    183531 non-null int64\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataframe.info()\n",
    "#contains null values for name, reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values with empty string\n",
    "dataframe = dataframe.fillna({'review':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove punctuations\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator) \n",
    "\n",
    "dataframe[\"review_without_punctuation\"] = dataframe['review'].apply(lambda x : remove_punctuation(x))\n",
    "dataframe=dataframe[[\"name\",\"review_without_punctuation\",\"rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore all reviews with rating = 3, since they tend to have a neutral sentiment\n",
    "dataframe=dataframe[dataframe[\"rating\"]!=3].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews with a rating of 4 or higher to be positive reviews, while the ones with rating of 2 \n",
    "#or lower are negative. For the sentiment column, we use +1 for the positive class label and -1 \n",
    "#for the negative class label\n",
    "dataframe['sentiment'] = dataframe['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test-train data\n",
    "with open('module-2-assignment-test-idx.json') as test_data_file:    \n",
    "    test_data_idx = json.load(test_data_file)\n",
    "with open('module-2-assignment-train-idx.json') as train_data_file:    \n",
    "    train_data_idx = json.load(train_data_file)\n",
    "\n",
    "train_data = dataframe.iloc[train_data_idx]\n",
    "test_data = dataframe.iloc[test_data_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the word count vector for each review_without_punctuations\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_without_punctuation'])\n",
    "test_matrix = vectorizer.transform(test_data['review_without_punctuation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic model fit\n",
    "sentiment_model = LogisticRegression(solver='liblinear',n_jobs=1)\n",
    "sentiment_model.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUIZ Predicting sentiment from product reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "How many weights are greater than or equal to 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sentiment_model.coef_ >= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Of the three data points in sample_test_data, which one has the lowest probability of being classified as a positive review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n",
      "[[3.67713366e-03 9.96322866e-01]\n",
      " [9.59664165e-01 4.03358355e-02]\n",
      " [9.99970284e-01 2.97164132e-05]]\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data.iloc[10:13]\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_without_punctuation'])\n",
    "print(sentiment_model.classes_)\n",
    "print(sentiment_model.predict_proba(sample_test_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: Third"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Which of the following products are represented in the 20 most positive reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: Third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Britax Decathlon Convertible Car Seat, Tiffany']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"postive_review_probability\"]=[x[1] for x in np.asarray(sentiment_model.predict_proba(test_matrix))]\n",
    "top_20=list(test_data.sort_values(\"postive_review_probability\",ascending=False)[:20][\"name\"])\n",
    "options_list=[\"Snuza Portable Baby Movement Monitor\",\"MamaDoo Kids Foldable Play Yard Mattress Topper, Blue\",\"Britax Decathlon Convertible Car Seat, Tiffany\",\"Safety 1st Exchangeable Tip 3 in 1 Thermometer\"]\n",
    "[x for x in options_list if x in top_20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "Which of the following products are represented in the 20 most negative reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit',\n",
       " 'Peg-Perego Tatamia High Chair, White Latte',\n",
       " 'Safety 1st High-Def Digital Monitor']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"postive_review_probability\"]=[x[0] for x in np.asarray(sentiment_model.predict_proba(test_matrix))]\n",
    "top_20=list(test_data.sort_values(\"postive_review_probability\",ascending=False)[:20][\"name\"])\n",
    "options_list=[\"The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit\",\"JP Lizzy Chocolate Ice Classic Tote Set\",\"Peg-Perego Tatamia High Chair, White Latte\",\"Safety 1st High-Def Digital Monitor\"]\n",
    "[x for x in options_list if x in top_20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5\n",
    "What is the accuracy of the sentiment_model on the test_data? Round your answer to 2 decimal places (e.g. 0.76)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    pred_y=model.predict(data)\n",
    "    correct=np.sum(pred_y==true_labels)\n",
    "    accuracy=round(correct/len(true_labels),2)\n",
    "    return accuracy\n",
    "\n",
    "get_classification_accuracy(sentiment_model,test_matrix,test_data[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6\n",
    "Does a higher accuracy value on the training_data always imply that the classifier is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: No, higher accuracy on training data does not necessarily imply that the classifier is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7\n",
    "Consider the coefficients of simple_model. There should be 21 of them, an intercept term + one for each word in significant_words.How many of the 20 coefficients (corresponding to the 20 significant_words and excluding the intercept term) are positive for the simple_model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "\n",
    "\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 significant words\n",
    "train_matrix_sub = vectorizer_word_subset.fit_transform(train_data['review_without_punctuation'])\n",
    "test_matrix_sub = vectorizer_word_subset.transform(test_data['review_without_punctuation'])\n",
    "#Logistic model fit\n",
    "simple_model = LogisticRegression(solver='liblinear',n_jobs=1)\n",
    "simple_model.fit(train_matrix_sub, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_coefficient = pd.DataFrame({'word':significant_words,'simple_model_coefficient':simple_model.coef_.flatten()}).sort_values(['simple_model_coefficient'], ascending=False).reset_index(drop=True)\n",
    "len(simple_model_coefficient[simple_model_coefficient[\"simple_model_coefficient\"]>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8\n",
    "Are the positive words in the simple_model also positive words in the sentiment_model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>simple_model_coefficient</th>\n",
       "      <th>sentimental_model_coefficient</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loves</th>\n",
       "      <td>1.673074</td>\n",
       "      <td>1.043761e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>1.509812</td>\n",
       "      <td>-6.860067e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1.363690</td>\n",
       "      <td>2.670837e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>easy</th>\n",
       "      <td>1.192538</td>\n",
       "      <td>-5.468800e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>0.944000</td>\n",
       "      <td>6.483661e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>0.520186</td>\n",
       "      <td>-3.146887e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>0.503760</td>\n",
       "      <td>6.160998e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0.190909</td>\n",
       "      <td>2.129163e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>0.085513</td>\n",
       "      <td>8.179701e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>0.058855</td>\n",
       "      <td>5.519557e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>less</th>\n",
       "      <td>-0.209563</td>\n",
       "      <td>4.175778e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>-0.320556</td>\n",
       "      <td>2.334292e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>would</th>\n",
       "      <td>-0.362167</td>\n",
       "      <td>2.199556e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>-0.511380</td>\n",
       "      <td>7.929719e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>-0.621169</td>\n",
       "      <td>1.079507e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>-0.898031</td>\n",
       "      <td>5.781430e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broke</th>\n",
       "      <td>-1.651576</td>\n",
       "      <td>-7.191992e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waste</th>\n",
       "      <td>-2.033699</td>\n",
       "      <td>5.762655e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>return</th>\n",
       "      <td>-2.109331</td>\n",
       "      <td>1.987394e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disappointed</th>\n",
       "      <td>-2.348298</td>\n",
       "      <td>2.854324e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              simple_model_coefficient  sentimental_model_coefficient\n",
       "word                                                                 \n",
       "loves                         1.673074                   1.043761e-02\n",
       "perfect                       1.509812                  -6.860067e-01\n",
       "love                          1.363690                   2.670837e-01\n",
       "easy                          1.192538                  -5.468800e-03\n",
       "great                         0.944000                   6.483661e-02\n",
       "little                        0.520186                  -3.146887e-01\n",
       "well                          0.503760                   6.160998e-07\n",
       "able                          0.190909                   2.129163e-01\n",
       "old                           0.085513                   8.179701e-03\n",
       "car                           0.058855                   5.519557e-02\n",
       "less                         -0.209563                   4.175778e-02\n",
       "product                      -0.320556                   2.334292e-02\n",
       "would                        -0.362167                   2.199556e-01\n",
       "even                         -0.511380                   7.929719e-02\n",
       "work                         -0.621169                   1.079507e-05\n",
       "money                        -0.898031                   5.781430e-04\n",
       "broke                        -1.651576                  -7.191992e-01\n",
       "waste                        -2.033699                   5.762655e-03\n",
       "return                       -2.109331                   1.987394e-01\n",
       "disappointed                 -2.348298                   2.854324e-03"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_coefficient=simple_model_coefficient.set_index(\"word\",drop=True)\n",
    "\n",
    "sentiment_model_coefficient = pd.DataFrame({'word':list(vectorizer.vocabulary_),'sentimental_model_coefficient':sentiment_model.coef_.flatten()}).sort_values(['sentimental_model_coefficient'], ascending=False).reset_index(drop=True)\n",
    "sentiment_model_coefficient=sentiment_model_coefficient[sentiment_model_coefficient[\"word\"].isin(significant_words)].set_index(\"word\",drop=True)\n",
    "\n",
    "simple_model_coefficient.join(sentiment_model_coefficient,on=\"word\",how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9\n",
    "Which model (sentiment_model or simple_model) has higher accuracy on the TRAINING set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__:    Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Model:  0.97\n",
      "Simple Model:  0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment Model: \",get_classification_accuracy(sentiment_model,train_matrix,train_data[\"sentiment\"]))\n",
    "print(\"Simple Model: \",get_classification_accuracy(simple_model,train_matrix_sub,train_data[\"sentiment\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10\n",
    "Which model (sentiment_model or simple_model) has higher accuracy on the TEST set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: Sentiment Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Model:  0.93\n",
      "Simple Model:  0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment Model: \",get_classification_accuracy(sentiment_model,test_matrix,test_data[\"sentiment\"]))\n",
    "print(\"Simple Model: \",get_classification_accuracy(simple_model,test_matrix_sub,test_data[\"sentiment\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11\n",
    "Enter the accuracy of the majority class classifier model on the test_data. Round your answer to two decimal places (e.g. 0.76)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>5241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  sentiment  count\n",
       "0             -1   5241\n",
       "1              1  28095"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find Majority Class\n",
    "freq=pd.crosstab(test_data[\"sentiment\"],columns=[\"count\"]).reset_index()\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model:  0.84\n"
     ]
    }
   ],
   "source": [
    "#Majority class=1\n",
    "baseline_model=round(freq[freq[\"sentiment\"]==1][\"count\"].values[0]/freq[\"count\"].sum(),2)\n",
    "print(\"Baseline Model: \", baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12\n",
    "Is the sentiment_model definitely better than the majority class classifier (the baseline)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ans__: Yes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
